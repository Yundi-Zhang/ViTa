{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from datasets.preprocessing_tabular.tabular_utils import *\n",
    "\n",
    "IMAGING_SUBJ_PATH = \"./datasets/data_files/image_files/recon_cmr_subject_paths_50k.pkl\"\n",
    "BIOMARKER_TABULAR_DIR=\"Phenotype data you have\"\n",
    "ALL_CARDIAC_FEATURES_PATH = \"Cardiac features you have\"\n",
    "CLEANED_FEATURES_PATH = \"Clean tabular data you have\"\n",
    "RAW_TABULAR_DATA_PATH = \"./datasets/data_files/tabular_files/raw_tab.csv\"\n",
    "RAW_SCALED_TABULAR_DATA_PATH = \"./datasets/data_files/tabular_files/raw_scaled_tab.csv\"\n",
    "PREPROCESSED_TABULAR_DATA_PATH = \"./datasets/data_files/tabular_files/preprocessed_tab_nonorm_noonehot.csv\"\n",
    "\n",
    "NORMALIZATION = True\n",
    "ONE_HOT_ENCODE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"datasets/data_files/tabular_files/feature_names.json\"\n",
    "feature_data = {\n",
    "    \"numerical\": [\n",
    "        'Age when attended assessment centre-2.0',\n",
    "        'Pulse wave Arterial Stiffness index-2.0',\n",
    "        'Systolic blood pressure-2.mean',\n",
    "        'Diastolic blood pressure-2.mean',\n",
    "        'Pulse rate-2.mean',\n",
    "        'Body fat percentage-2.0',\n",
    "        'Whole body fat mass-2.0',\n",
    "        'Whole body fat-free mass-2.0',\n",
    "        'Whole body water mass-2.0',\n",
    "        'Body mass index (BMI)-2.0',\n",
    "        'Cooked vegetable intake-2.0',\n",
    "        'Salad / raw vegetable intake-2.0',\n",
    "        'Cardiac operations performed',\n",
    "        'Total mass-2.0',\n",
    "        'Basal metabolic rate-2.0',\n",
    "        'Impedance of whole body-2.0',\n",
    "        'Waist circumference-2.0',\n",
    "        'Hip circumference-2.0',\n",
    "        'Standing height-2.0',\n",
    "        'Height-2.0',\n",
    "        'Sitting height-2.0',\n",
    "        'Weight-2.0',\n",
    "        'Ventricular rate-2.0',\n",
    "        'P duration-2.0',\n",
    "        'QRS duration-2.0',\n",
    "        'PQ interval-2.0',\n",
    "        'RR interval-2.0',\n",
    "        'PP interval-2.0',\n",
    "        'Cardiac output-2.0',\n",
    "        'Cardiac index-2.0',\n",
    "        'Average heart rate-2.0',\n",
    "        'Body surface area-2.0',\n",
    "        'Duration of walks-2.0',\n",
    "        'Duration of moderate activity-2.0',\n",
    "        'Duration of vigorous activity-2.0',\n",
    "        'Time spent watching television (TV)-2.0',\n",
    "        'Time spent using computer-2.0',\n",
    "        'Time spent driving-2.0',\n",
    "        'Heart rate during PWA-2.0',\n",
    "        'Systolic brachial blood pressure during PWA-2.0',\n",
    "        'Diastolic brachial blood pressure during PWA-2.0',\n",
    "        'Peripheral pulse pressure during PWA-2.0',\n",
    "        'Central systolic blood pressure during PWA-2.0',\n",
    "        'Central pulse pressure during PWA-2.0',\n",
    "        'Number of beats in waveform average for PWA-2.0',\n",
    "        'Central augmentation pressure during PWA-2.0',\n",
    "        'Augmentation index for PWA-2.0',\n",
    "        'Cardiac output during PWA-2.0',\n",
    "        'End systolic pressure during PWA-2.0',\n",
    "        'End systolic pressure index during PWA-2.0',\n",
    "        'Stroke volume during PWA-2.0',\n",
    "        'Mean arterial pressure during PWA-2.0',\n",
    "        'Cardiac index during PWA-2.0',\n",
    "        'Sleep duration-2.0',\n",
    "        'Exposure to tobacco smoke at home-2.0',\n",
    "        'Exposure to tobacco smoke outside home-2.0',\n",
    "        'Pack years of smoking-2.0',\n",
    "        'Pack years adult smoking as proportion of life span exposed to smoking-2.0',\n",
    "        'LVESV (mL)',\n",
    "        'LVSV (mL)',\n",
    "        'LVEF (%)',\n",
    "        'LVCO (L/min)',\n",
    "        'LVM (g)',\n",
    "        'RVEDV (mL)',\n",
    "        'RVESV (mL)',\n",
    "        'RVSV (mL)',\n",
    "        'RVEF (%)',\n",
    "        'LAV max (mL)',\n",
    "        'LAV min (mL)',\n",
    "        'LASV (mL)',\n",
    "        'LAEF (%)',\n",
    "        'RAV max (mL)',\n",
    "        'RAV min (mL)',\n",
    "        'RASV (mL)',\n",
    "        'RAEF (%)',\n",
    "    ],\n",
    "    \n",
    "    \"single_categorical\": [\n",
    "        'Worrier / anxious feelings-2.0',\n",
    "        'Shortness of breath walking on level ground-2.0',\n",
    "        'Sex-0.0',\n",
    "        'Diabetes diagnosis',\n",
    "        'Heart attack diagnosed by doctor',\n",
    "        'Angina diagnosed by doctor',\n",
    "        'Stroke diagnosed by doctor',\n",
    "        'High blood pressure diagnosed by doctor',\n",
    "        'Cholesterol lowering medication regularly taken',\n",
    "        'Blood pressure medication regularly taken',\n",
    "        'Insulin medication regularly taken',\n",
    "        'Hormone replacement therapy medication regularly taken',\n",
    "        'Oral contraceptive pill or minipill medication regularly taken',\n",
    "        'Pace-maker-2.0',\n",
    "        'Ever had diabetes (Type I or Type II)-0.0',\n",
    "        'Long-standing illness, disability or infirmity-2.0',\n",
    "        'Tense / \\'highly strung\\'-2.0',\n",
    "        'Ever smoked-2.0'\n",
    "        ],\n",
    "\n",
    "\n",
    "    \"multi_categorical\": {\n",
    "        'Sleeplessness / insomnia-2.0': [3, True],\n",
    "        'Frequency of heavy DIY in last 4 weeks-2.0': [7, False],\n",
    "        'Alcohol intake frequency.-2.0': [6, True],\n",
    "        'Processed meat intake-2.0': [6, False],\n",
    "        'Beef intake-2.0': [6, False],\n",
    "        'Pork intake-2.0': [6, False],\n",
    "        'Lamb/mutton intake-2.0': [6, False],\n",
    "        'Overall health rating-2.0': [4, True],\n",
    "        'Alcohol usually taken with meals-2.0': [3, False],\n",
    "        'Alcohol drinker status-2.0': [3, False],\n",
    "        'Frequency of drinking alcohol-0.0': [5, False],\n",
    "        'Frequency of consuming six or more units of alcohol-0.0': [5, True],\n",
    "        'Amount of alcohol drunk on a typical drinking day-0.0': [6, False],\n",
    "        'Falls in the last year-2.0': [3, True],\n",
    "        'Weight change compared with 1 year ago-2.0': [3, False],\n",
    "        'Number of days/week walked 10+ minutes-2.0': [8, False],\n",
    "        'Number of days/week of moderate physical activity 10+ minutes-2.0': [8, False],\n",
    "        'Number of days/week of vigorous physical activity 10+ minutes-2.0': [8, False],\n",
    "        'Usual walking pace-2.0': [3, True],\n",
    "        'Frequency of stair climbing in last 4 weeks-2.0': [6, False],\n",
    "        'Frequency of walking for pleasure in last 4 weeks-2.0': [7, False],\n",
    "        'Duration walking for pleasure-2.0': [8, False],\n",
    "        'Frequency of strenuous sports in last 4 weeks-2.0': [7, False],\n",
    "        'Duration of strenuous sports-2.0': [8, False],\n",
    "        'Duration of light DIY-2.0': [8, False],\n",
    "        'Duration of heavy DIY-2.0': [8, False],\n",
    "        'Frequency of other exercises in last 4 weeks-2.0': [7, False],\n",
    "        'Duration of other exercises-2.0': [8, False],\n",
    "        'Current tobacco smoking-2.0': [3, False],\n",
    "        'Past tobacco smoking-2.0': [4, True],\n",
    "        'Smoking/smokers in household-2.0': [3, False],\n",
    "        'Smoking status-2.0': [3, False]\n",
    "    }\n",
    "}\n",
    "with open(SAVE_PATH, 'w') as f:\n",
    "    json.dump(feature_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate clean table based on the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardiac_features_to_vector_no_onehot_df(df, feature_data):\n",
    "    vec = []\n",
    "    indices = {}\n",
    "    vec.append(df['eid'])\n",
    "    \n",
    "    # Numerical\n",
    "    for name in feature_data[\"numerical\"]:\n",
    "        vec.append(df[name])\n",
    "    indices[\"numerical\"] = list(range(len(vec)))\n",
    "    \n",
    "    # Single categorical\n",
    "    for name in feature_data[\"single_categorical\"]:\n",
    "        vec.append(df[name].apply(clean_categorical))\n",
    "    indices[\"categorical_single\"] = list(range((indices[\"numerical\"][-1]+1), len(vec)))\n",
    "\n",
    "    # Multiple categorical\n",
    "    for name, data in feature_data[\"multi_categorical\"].items():\n",
    "        feature_values = df[name].apply(clean_categorical)\n",
    "        use_base = data[1]\n",
    "        if use_base and not ONE_HOT_ENCODE:\n",
    "            feature_values = feature_values.apply(lambda x: x - 1 if pd.notnull(x) else x)\n",
    "        vec.append(feature_values)\n",
    "    indices[\"categorical_multi\"] = list(range((indices[\"categorical_single\"][-1]+1), len(vec)))\n",
    "    return vec, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_one_hot_encode_df(df):\n",
    "    vec = []\n",
    "    num_classes = [3, 7, 6, 6, 6, 6, 6, 4, 3, 3, 5, 5, 6, 3, 3, 8, 8, 8, 3, 6, 7, 8, 7, 8, 8, 8, 7, 8, 3, 4, 3, 3]\n",
    "\n",
    "    vec.append(df['Sleeplessness / insomnia-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=3, one_based=True)))\n",
    "    vec.append(df['Frequency of heavy DIY in last 4 weeks-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=7)))\n",
    "    vec.append(df['Alcohol intake frequency.-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=6, one_based=True)))\n",
    "    vec.append(df['Processed meat intake-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=6)))\n",
    "    vec.append(df['Beef intake-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=6)))\n",
    "    vec.append(df['Pork intake-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=6)))\n",
    "    vec.append(df['Lamb/mutton intake-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=6)))\n",
    "    vec.append(df['Overall health rating-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=4, one_based=True)))\n",
    "    vec.append(df['Alcohol usually taken with meals-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=3)))\n",
    "    vec.append(df['Alcohol drinker status-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=3)))\n",
    "    vec.append(df['Frequency of drinking alcohol-0.0'].apply(lambda col: one_hot_encode(value=col, num_classes=5)))\n",
    "    vec.append(df['Frequency of consuming six or more units of alcohol-0.0'].apply(lambda col: one_hot_encode(value=col, num_classes=5, one_based=True)))\n",
    "    vec.append(df['Amount of alcohol drunk on a typical drinking day-0.0'].apply(lambda col: one_hot_encode(value=col, num_classes=6, one_based=False)))\n",
    "    vec.append(df['Falls in the last year-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=3, one_based=True)))\n",
    "    vec.append(df['Weight change compared with 1 year ago-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=3)))\n",
    "    vec.append(df['Number of days/week walked 10+ minutes-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=8)))\n",
    "    vec.append(df['Number of days/week of moderate physical activity 10+ minutes-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=8)))\n",
    "    vec.append(df['Number of days/week of vigorous physical activity 10+ minutes-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=8)))\n",
    "    vec.append(df['Usual walking pace-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=3, one_based=True)))\n",
    "    vec.append(df['Frequency of stair climbing in last 4 weeks-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=6)))\n",
    "    vec.append(df['Frequency of walking for pleasure in last 4 weeks-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=7)))\n",
    "    vec.append(df['Duration walking for pleasure-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=8)))\n",
    "    vec.append(df['Frequency of strenuous sports in last 4 weeks-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=7)))\n",
    "    vec.append(df['Duration of strenuous sports-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=8)))\n",
    "    vec.append(df['Duration of light DIY-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=8)))\n",
    "    vec.append(df['Duration of heavy DIY-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=8)))\n",
    "    vec.append(df['Frequency of other exercises in last 4 weeks-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=7)))\n",
    "    vec.append(df['Duration of other exercises-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=8)))\n",
    "    vec.append(df['Current tobacco smoking-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=3)))\n",
    "    vec.append(df['Past tobacco smoking-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=4, one_based=True)))\n",
    "    vec.append(df['Smoking/smokers in household-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=3)))\n",
    "    vec.append(df['Smoking status-2.0'].apply(lambda col: one_hot_encode(value=col, num_classes=3)))\n",
    "    one_hot_df = pd.concat(vec,axis=1)\n",
    "    one_hot_df = one_hot_df.reset_index(drop=True)\n",
    "    return one_hot_df, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_df = pd.read_csv(CLEANED_FEATURES_PATH)\n",
    "\n",
    "df_vec, indices = cardiac_features_to_vector_no_onehot_df(raw_data_df, feature_data)\n",
    "df = pd.concat(df_vec,axis=1)\n",
    "df = df.reset_index(drop=True)\n",
    "print(f\"{indices.keys()}\")\n",
    "df.to_csv(RAW_TABULAR_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute NaN with mean values / most frequenct values and apply z-score standard deviation\n",
    "### z-score standard normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute numerical missing values with the mean\n",
    "eid_column = df[\"eid\"]\n",
    "\n",
    "raw_numerical_df = df.iloc[:, indices[\"numerical\"][1:]]\n",
    "singlecategorical_df = df.iloc[:, indices[\"categorical_single\"]]\n",
    "multicategorical_df = df.iloc[:, indices[\"categorical_multi\"]]\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "imp_mean.fit(raw_numerical_df)\n",
    "numerical_df = imp_mean.transform(raw_numerical_df)\n",
    "numerical_df = pd.DataFrame(numerical_df, columns=df.columns[indices[\"numerical\"][1:]])\n",
    "\n",
    "# z-score standard normalization\n",
    "if NORMALIZATION:\n",
    "    scaler = StandardScaler()\n",
    "    normalized_df = scaler.fit_transform(numerical_df)\n",
    "    numerical_df = pd.DataFrame(normalized_df, columns=numerical_df.columns)\n",
    "    # Save the scaler\n",
    "    with open('data_files/tabular_files/scaler.pkl', 'wb') as file:\n",
    "        pickle.dump(scaler, file)\n",
    "# Save the scaled version of the raw data. No data imputation!\n",
    "raw_numerical_df = df.iloc[:, indices[\"numerical\"][1:]]\n",
    "raw_categorical_df = df.iloc[:, indices[\"numerical\"][1:]]\n",
    "raw_scaled_numerical_df = numerical_df.where(~raw_numerical_df.isna(), np.nan)\n",
    "raw_scaled_df = pd.concat([eid_column, raw_scaled_numerical_df, singlecategorical_df, multicategorical_df], axis=1)\n",
    "raw_scaled_df.to_csv(RAW_SCALED_TABULAR_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Impute caregorical missing values with the most frequent value\n",
    "categorical_indices = indices[\"categorical_single\"] + indices[\"categorical_multi\"]\n",
    "categorical_df = df.iloc[:, categorical_indices]\n",
    "imp_most_freq = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\", keep_empty_features=True)\n",
    "imp_most_freq.fit(categorical_df)\n",
    "df.iloc[:, categorical_indices] = imp_most_freq.transform(df.iloc[:, categorical_indices])\n",
    "\n",
    "# One hot encode and expand the multiple categorical columns\n",
    "if ONE_HOT_ENCODE:\n",
    "    multi_c_df, num_classes = df_to_one_hot_encode_df(multicategorical_df)\n",
    "    expanded_vecs = []\n",
    "    for col_name in multi_c_df.columns:\n",
    "        expanded_vec = pd.DataFrame(list(multi_c_df[col_name]), \n",
    "                                    columns=[f\"{col_name}_{i}\" for i in range(len(multi_c_df[col_name][0]))])\n",
    "        expanded_vecs.append(expanded_vec)\n",
    "    multicategorical_df = pd.concat(expanded_vecs, axis=1) \n",
    "\n",
    "# Combine df\n",
    "preprocessed_df = pd.concat([eid_column, numerical_df, singlecategorical_df, multicategorical_df], axis=1)\n",
    "preprocessed_df.to_csv(PREPROCESSED_TABULAR_DATA_PATH, index=False)\n",
    "print(preprocessed_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmae_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
