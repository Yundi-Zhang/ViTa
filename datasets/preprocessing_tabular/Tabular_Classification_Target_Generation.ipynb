{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "# from preprocessing_ukbb.Utils import check_or_save\n",
    "\n",
    "TABULAR_BASE = \"Raw tabular data you have\"\n",
    "DATAFILE_BASE = \"./datasets/data_files/tabular_files\"\n",
    "CLEANED_FEATURES_PATH = \"Clean tabular data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dir_path = Path(\"imaging data path\")\n",
    "with open(\"datasets/data_files/image_files/subj_ids_with_required_size.pkl\", \"rb\") as f:\n",
    "    all_image_ids = pickle.load(f)\n",
    "\n",
    "data_df = pd.read_csv(CLEANED_FEATURES_PATH)\n",
    "date_attended_imaging = pd.read_csv(join(TABULAR_BASE,'col67.txt'))\n",
    "date_attended_imaging.rename(columns={'eid':'eid','53-2.0':'Date of attending imaging centre-2.0'},inplace=True)\n",
    "data_df_extended = data_df.merge(date_attended_imaging, left_on='eid', right_on='eid', how='inner')\n",
    "assert len(data_df_extended) == len(data_df)\n",
    "\n",
    "for target_name in ['CAD', 'Stroke', 'Hypertension', 'Infarct', 'Diabetes']:\n",
    "    if target_name == 'CAD':\n",
    "        target = ['I200', 'I201', 'I208', 'I209', 'I220', 'I221', 'I228', 'I229', 'I210', 'I211', 'I212', 'I213', 'I214', \n",
    "                  'I219','I240', 'I248', 'I249', 'I250', 'I251', 'I252', 'I253', 'I254', 'I255', 'I256', 'I258', 'I259',]\n",
    "    elif target_name == 'Stroke':\n",
    "        target = ['I630', 'I631', 'I632', 'I633', 'I634', 'I635', 'I636', 'I638', 'I639']\n",
    "    elif target_name == 'Hypertension':\n",
    "        target = ['I10', 'I110', 'I119', 'I120', 'I129', 'I130', 'I131', 'I132', 'I139', 'I150', 'I151', 'I152', 'I158', 'I159']\n",
    "    elif target_name == 'Infarct':\n",
    "        target = ['I210', 'I211', 'I212', 'I213', 'I214', 'I219', 'I252'] # change according to the paper\n",
    "    elif target_name == 'Diabetes':\n",
    "        target = ['E100','E101','E102','E103','E104','E105','E106','E107','E108','E109','E110','E111','E112','E113','E114','E115','E116','E117','E118','E119','E121','E123','E125','E128','E129','E130','E131','E132','E133','E134','E135','E136','E137','E138','E139','E140','E141','E142','E143','E144','E145','E146','E147','E148','E149']\n",
    "\n",
    "    array_length = 243\n",
    "    diag_name = 'Diagnoses - ICD10-0.'\n",
    "    date_name = 'Date of first in-patient diagnosis - ICD10-0.'\n",
    "    all_target_dates = []\n",
    "    all_target_indices = []\n",
    "    all_target_ids = []\n",
    "    for i in range(array_length):\n",
    "        all_target_dates.extend(list(data_df[data_df[f'{diag_name}{i}'].isin(target)][f'{date_name}{i}']))\n",
    "        all_target_indices.extend(list(data_df[data_df[f'{diag_name}{i}'].isin(target)].index))\n",
    "        all_target_ids.extend(list(data_df[data_df[f'{diag_name}{i}'].isin(target)]['eid']))\n",
    "\n",
    "    date_attending_centre = []\n",
    "    for i in all_target_indices:\n",
    "        date_attending_centre.append(data_df_extended.loc[i,'Date of attending imaging centre-2.0'])\n",
    "    date_attending_centre = pd.Series(date_attending_centre).astype('datetime64[ns]')\n",
    "\n",
    "    target_df = pd.DataFrame({'eid':all_target_ids,'target date':all_target_dates,'imaging date':date_attending_centre})\n",
    "    for time in ['all']:\n",
    "        if time == 'future':\n",
    "            target_ids = target_df[target_df['target date']>target_df['imaging date']]['eid']\n",
    "        elif time == 'past':\n",
    "            target_ids = target_df[target_df['target date']<target_df['imaging date']]['eid']\n",
    "        else:\n",
    "            target_ids = target_df['eid']\n",
    "            \n",
    "    labels_data = {\"eid\": [], f\"Diagnosed_{target_name}\": []}\n",
    "    labels_data[\"eid\"] = data_df[\"eid\"]\n",
    "    l = []\n",
    "    for eid in list(labels_data[\"eid\"]):\n",
    "        l.append(int(eid in list(target_df['eid'])))\n",
    "    print(sum(l))\n",
    "    labels_data[f\"Diagnosed_{target_name}\"] = l\n",
    "    labels_df = pd.DataFrame(labels_data)\n",
    "    labels_df.to_csv(join(DATAFILE_BASE, f'labels_{target_name}.csv'), index=False)\n",
    "\n",
    "    # Split into train, val, and test image paths accirding Diagnosed label\n",
    "    labels_with_image_df = labels_df[labels_df[\"eid\"].isin(all_image_ids)]\n",
    "    df_train, df_temp = train_test_split(labels_with_image_df, test_size=2000, \n",
    "                                        stratify=labels_with_image_df[f'Diagnosed_{target_name}'], \n",
    "                                        random_state=42)\n",
    "    df_val, df_test = train_test_split(df_temp, test_size=1000, stratify=df_temp[f'Diagnosed_{target_name}'], random_state=42)\n",
    "    image_paths = {}\n",
    "    for set in [\"train\", \"val\", \"test\"]:\n",
    "        df = eval(f\"df_{set}\")\n",
    "        positive_num = sum(df[f'Diagnosed_{target_name}'])\n",
    "        set_paths =[]\n",
    "        for i in df[\"eid\"]:\n",
    "            set_paths.append(dir_path / str(i) / \"processed_seg_allax.npz\")\n",
    "        print(f\"{target_name}_{set}: {positive_num}/\", len(set_paths))\n",
    "        image_paths[set] = set_paths\n",
    "    with open(f\"datasets/data_files/image_files/recon_cmr_subject_paths_50k_{target_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(image_paths, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'High_blood_pressure'\n",
    "target = 'Age high blood pressure diagnosed-2.0'\n",
    "labels_data = {\"eid\": [], f\"Diagnosed_{target_name}\": []}\n",
    "labels_data[\"eid\"] = data_df[\"eid\"]\n",
    "l = []\n",
    "for eid in list(labels_data[\"eid\"]):\n",
    "    l.append(int(~data_df[data_df[\"eid\"] == eid][target].isna()))\n",
    "print(sum(l))\n",
    "labels_data[f\"Diagnosed_{target_name}\"] = l\n",
    "labels_df = pd.DataFrame(labels_data)\n",
    "labels_df.to_csv(join(DATAFILE_BASE, f'labels_{target_name}.csv'), index=False)\n",
    "\n",
    "# Split into train, val, and test image paths accirding Diagnosed label\n",
    "labels_with_image_df = labels_df[labels_df[\"eid\"].isin(all_image_ids)]\n",
    "df_train, df_temp = train_test_split(labels_with_image_df, test_size=2000, \n",
    "                                    stratify=labels_with_image_df[f'Diagnosed_{target_name}'], \n",
    "                                    random_state=42)\n",
    "df_val, df_test = train_test_split(df_temp, test_size=1000, stratify=df_temp[f'Diagnosed_{target_name}'], random_state=42)\n",
    "image_paths = {}\n",
    "for set in [\"train\", \"val\", \"test\"]:\n",
    "    df = eval(f\"df_{set}\")\n",
    "    positive_num = sum(df[f'Diagnosed_{target_name}'])\n",
    "    set_paths =[]\n",
    "    for i in df[\"eid\"]:\n",
    "        set_paths.append(dir_path / str(i) / \"processed_seg_allax.npz\")\n",
    "    print(f\"{target_name}_{set}: {positive_num}/\", len(set_paths))\n",
    "    image_paths[set] = set_paths\n",
    "with open(f\"datasets/data_files/image_files/recon_cmr_subject_paths_50k_{target_name}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(image_paths, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmae_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
